{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b472fa91",
   "metadata": {},
   "source": [
    "# PyTorch Tutorial: From Zero to Hero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0d7091",
   "metadata": {},
   "source": [
    "## 1. Installation & Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e3080b",
   "metadata": {},
   "source": [
    "### CPU-Only Version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75863ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31merror\u001b[0m: \u001b[1mexternally-managed-environment\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m This environment is externally managed\n",
      "\u001b[31m╰─>\u001b[0m To install Python packages system-wide, try apt install\n",
      "\u001b[31m   \u001b[0m python3-xyz, where xyz is the package you are trying to\n",
      "\u001b[31m   \u001b[0m install.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Debian-packaged Python package,\n",
      "\u001b[31m   \u001b[0m create a virtual environment using python3 -m venv path/to/venv.\n",
      "\u001b[31m   \u001b[0m Then use path/to/venv/bin/python and path/to/venv/bin/pip. Make\n",
      "\u001b[31m   \u001b[0m sure you have python3-full installed.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Debian packaged Python application,\n",
      "\u001b[31m   \u001b[0m it may be easiest to use pipx install xyz, which will manage a\n",
      "\u001b[31m   \u001b[0m virtual environment for you. Make sure you have pipx installed.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m See /usr/share/doc/python3.12/README.venv for more information.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\n",
      "\u001b[1;36mhint\u001b[0m: See PEP 668 for the detailed specification.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caacd0f9",
   "metadata": {},
   "source": [
    "### GPU Version (CUDA 11.8):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec085eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31merror\u001b[0m: \u001b[1mexternally-managed-environment\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m This environment is externally managed\n",
      "\u001b[31m╰─>\u001b[0m To install Python packages system-wide, try apt install\n",
      "\u001b[31m   \u001b[0m python3-xyz, where xyz is the package you are trying to\n",
      "\u001b[31m   \u001b[0m install.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Debian-packaged Python package,\n",
      "\u001b[31m   \u001b[0m create a virtual environment using python3 -m venv path/to/venv.\n",
      "\u001b[31m   \u001b[0m Then use path/to/venv/bin/python and path/to/venv/bin/pip. Make\n",
      "\u001b[31m   \u001b[0m sure you have python3-full installed.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Debian packaged Python application,\n",
      "\u001b[31m   \u001b[0m it may be easiest to use pipx install xyz, which will manage a\n",
      "\u001b[31m   \u001b[0m virtual environment for you. Make sure you have pipx installed.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m See /usr/share/doc/python3.12/README.venv for more information.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\n",
      "\u001b[1;36mhint\u001b[0m: See PEP 668 for the detailed specification.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e01cc5",
   "metadata": {},
   "source": [
    "* Note: For other CUDA versions, visit the official PyTorch website to get the correct command.​"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411a0a60",
   "metadata": {},
   "source": [
    "Using conda\n",
    "This is often preferred in scientific computing environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "557bcdf5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The python kernel does not appear to be a conda environment.  Please use ``%pip install`` instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minstall pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py:2456\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2454\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2455\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2456\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2458\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2459\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2460\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/magics/packaging.py:26\u001b[0m, in \u001b[0;36mis_conda_environment.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# TODO: does this need to change on windows?\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Path(sys\u001b[38;5;241m.\u001b[39mprefix, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconda-meta\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe python kernel does not appear to be a conda environment.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use ``\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mpip install`` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     29\u001b[0m     )\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mValueError\u001b[0m: The python kernel does not appear to be a conda environment.  Please use ``%pip install`` instead."
     ]
    }
   ],
   "source": [
    "conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91770caa",
   "metadata": {},
   "source": [
    "Verify Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1cc97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ccd273",
   "metadata": {},
   "source": [
    "## 2. Introduction to Tensors\n",
    "Tensors are the core data structure in PyTorch. They are n-dimensional arrays, similar to NumPy's `ndarray`, but with two critical enhancements for deep learning:\n",
    "\n",
    "1. GPU Acceleration: Tensors can be processed on GPUs for massive speedups.\n",
    "\n",
    "2. Automatic Differentiation: PyTorch tracks operations on tensors to automatically compute gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02cb0bf",
   "metadata": {},
   "source": [
    "## 3. Tensor Creation & Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2623907d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# From a Python list\n",
    "tensor_from_list = torch.tensor([[1, 2], [3, 4]])\n",
    "\n",
    "# From a NumPy array\n",
    "numpy_array = np.array([[5, 6], [7, 8]])\n",
    "tensor_from_numpy = torch.from_numpy(numpy_array)\n",
    "\n",
    "# Using specialized functions\n",
    "zeros = torch.zeros(2, 3)                # 2x3 tensor of zeros\n",
    "ones = torch.ones(2, 3)                  # 2x3 tensor of ones\n",
    "rand_tensor = torch.rand(2, 3)           # Uniformly random values in [0, 1)\n",
    "randn_tensor = torch.randn(2, 3)         # Values from a standard normal distribution\n",
    "\n",
    "# Specifying data type (dtype)\n",
    "float_tensor = torch.tensor([1, 2, 3], dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc968ede",
   "metadata": {},
   "source": [
    "## 4. Tensor Operations\n",
    "Operations are syntactically similar to NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ce3e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1., 2.], [3., 4.]])\n",
    "b = torch.ones(2, 2)\n",
    "\n",
    "# Arithmetic\n",
    "print(\"Addition:\\n\", a + b)\n",
    "print(\"\\nElement-wise multiplication:\\n\", a * b)\n",
    "\n",
    "# Matrix Multiplication\n",
    "print(\"\\nMatrix multiplication:\\n\", a @ b) # or torch.matmul(a, b)\n",
    "\n",
    "# Transpose\n",
    "print(\"\\nTranspose:\\n\", a.T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed69a1b7",
   "metadata": {},
   "source": [
    "### Statistical Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f3f80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor([[2.0, 3.0, 7.0], [1.0, 5.0, 4.0]])\n",
    "\n",
    "# Global stats\n",
    "print(\"Mean:\", data.mean())\n",
    "print(\"Std Dev:\", data.std())\n",
    "print(\"Sum:\", data.sum())\n",
    "print(\"Min/Max:\", data.min(), data.max())\n",
    "\n",
    "# Operations along a dimension (axis)\n",
    "# dim=0 operates on columns, dim=1 operates on rows\n",
    "print(\"Mean of each column:\", data.mean(dim=0))\n",
    "print(\"Sum of each row:\", data.sum(dim=1))\n",
    "\n",
    "# Getting index of min/max\n",
    "# Find the flattened index of the minimum value\n",
    "idx_flat = data.argmin()\n",
    "rows, cols = data.shape\n",
    "row = idx_flat // cols\n",
    "col = idx_flat % cols\n",
    "print(f\"\\nMin value {data.min()} is at index [{row.item()}, {col.item()}]\")\n",
    "\n",
    "# Quantiles\n",
    "q = torch.tensor([0.25, 0.5, 0.75])\n",
    "print(\"Quantiles (25%, 50%, 75%):\", torch.quantile(data, q))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03573039",
   "metadata": {},
   "source": [
    "## 5. Indexing, Slicing & Reshaping\n",
    "These operations work just like in NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456a41b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(12).reshape(3, 4)\n",
    "\n",
    "# Slicing\n",
    "print(\"First row:\", x[0, :])\n",
    "print(\"Second column:\", x[:, 1])\n",
    "print(\"Sub-matrix:\\n\", x[0:2, 1:3])\n",
    "\n",
    "# Reshaping\n",
    "reshaped = x.reshape(2, 6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a26e62",
   "metadata": {},
   "source": [
    "## 6. NumPy Interoperability & Memory\n",
    "Converting between PyTorch and NumPy is seamless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385b7a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor to NumPy\n",
    "tensor = torch.ones(5)\n",
    "numpy_arr = tensor.numpy()\n",
    "\n",
    "# NumPy to Tensor\n",
    "numpy_arr = np.ones(5)\n",
    "tensor_from_np = torch.from_numpy(numpy_arr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f993e15",
   "metadata": {},
   "source": [
    "**Important:** `torch.from_numpy()` and `.numpy()` create objects that share the same underlying memory (when on the CPU). Modifying one will modify the other. To create a copy, use `.clone()` or `torch.tensor(numpy_arr)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475b2e3e",
   "metadata": {},
   "source": [
    "## 7. GPU Acceleration & Performance Benchmark\n",
    "The primary advantage of PyTorch is its ability to leverage GPUs.\n",
    "\n",
    "Moving Tensors to a Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9369edf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    print(\"GPU is available.\")\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print(\"GPU not available, using CPU.\")\n",
    "\n",
    "# Move a tensor to the selected device\n",
    "tensor = torch.randn(3, 3)\n",
    "tensor_on_device = tensor.to(device)\n",
    "print(f\"Tensor is on device: {tensor_on_device.device}\")\n",
    "\n",
    "# Move back to CPU\n",
    "tensor_cpu = tensor_on_device.cpu()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b97e6f",
   "metadata": {},
   "source": [
    "## CPU vs. GPU Speed Test\n",
    "This benchmark shows the speedup for large-scale computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af59949d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\"GPU not available for benchmark.\")\n",
    "\n",
    "N = 10_000_000\n",
    "x_cpu = torch.randn(N)\n",
    "x_gpu = x_cpu.to('cuda')\n",
    "\n",
    "# --- CPU Time ---\n",
    "start = time.time()\n",
    "y_cpu = x_cpu * 2.5\n",
    "cpu_time = time.time() - start\n",
    "\n",
    "# --- GPU Time ---\n",
    "# Synchronize to get accurate timing for GPU operations\n",
    "torch.cuda.synchronize()\n",
    "start = time.time()\n",
    "y_gpu = x_gpu * 2.5\n",
    "torch.cuda.synchronize()\n",
    "gpu_time = time.time() - start\n",
    "\n",
    "print(f\"CPU time: {cpu_time:.6f} s\")\n",
    "print(f\"GPU time: {gpu_time:.6f} s\")\n",
    "print(f\"Speedup: {cpu_time / gpu_time:.2f}x\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bbe08a",
   "metadata": {},
   "source": [
    "* Note: For small operations, the overhead of transferring data to the GPU can make it slower than the CPU. The benefit of a GPU is seen in large, parallelizable computations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19b9b8e",
   "metadata": {},
   "source": [
    "## 8. Automatic Differentiation (Autograd)\n",
    "PyTorch automatically computes gradients, which is essential for training models. Set `requires_grad=True` on tensors you want to differentiate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1424a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = x^2 + 3x + 5. Find dy/dx at x=2.\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = x**2 + 3*x + 5\n",
    "y.backward() # Computes gradients\n",
    "\n",
    "# The gradient is 2x + 3. At x=2, it is 7.\n",
    "print(f\"Gradient (dy/dx) at x=2 is: {x.grad}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b11a2b7",
   "metadata": {},
   "source": [
    "## 9. Building Neural Networks with nn.Module\n",
    "The `torch.nn` package provides layers and tools for building models. All custom models should inherit from `nn.Module`.​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c311da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 50) # Fully connected layer\n",
    "        self.fc2 = nn.Linear(50, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x)) # Apply ReLU activation\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleNet(input_size=10, output_size=1)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9e41ea",
   "metadata": {},
   "source": [
    "## 10. Training a Neural Network\n",
    "Training involves a loop where you feed data to the model, compute the error (loss), and update the model's weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791cfd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Sample data\n",
    "inputs = torch.randn(64, 10)\n",
    "targets = torch.randn(64, 1)\n",
    "\n",
    "# 1. Initialize model, loss function, and optimizer\n",
    "model = SimpleNet(10, 1)\n",
    "criterion = nn.MSELoss() # Mean Squared Error\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 2. Training loop\n",
    "for epoch in range(10):\n",
    "    optimizer.zero_grad()    # Reset gradients\n",
    "    outputs = model(inputs)  # Forward pass\n",
    "    loss = criterion(outputs, targets) # Compute loss\n",
    "    loss.backward()          # Backward pass (compute gradients)\n",
    "    optimizer.step()         # Update weights\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba7f849",
   "metadata": {},
   "source": [
    "## 11. Data Loading with DataLoader\n",
    "Dataset and `DataLoader` are utilities for efficiently handling large datasets by creating batches.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a783d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Create a dataset from tensors\n",
    "X = torch.randn(100, 10)\n",
    "y = torch.randn(100, 1)\n",
    "dataset = TensorDataset(X, y)\n",
    "\n",
    "# Create a DataLoader to serve batches of 32\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Iterate over batches in the training loop\n",
    "for batch_X, batch_y in dataloader:\n",
    "    # Training code for one batch goes here\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad84c1a",
   "metadata": {},
   "source": [
    "‍‍12. Summary: PyTorch vs. NumPy\n",
    "| Feature           | NumPy               | PyTorch              |\n",
    "|-------------------|---------------------|----------------------|\n",
    "| Data Structure    | `ndarray`           | `Tensor`             |\n",
    "| GPU Support       | ❌                  | ✅                   |\n",
    "| Autograd          | ❌                  | ✅                   |\n",
    "| Interoperability  | `.numpy()`          | `torch.from_numpy()` |\n",
    "| Ecosystem         | General scientific computing | Optimized for deep learning |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b7d85c",
   "metadata": {},
   "source": [
    "## Neural Networks: Linear Regression to 3D Velocity Field Modeling in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b229b6e",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e39a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch                 # Main PyTorch library\n",
    "import torch.nn as nn        # Neural network modules (layers, losses)\n",
    "import torch.optim as optim  # Optimization algorithms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db08e954",
   "metadata": {},
   "source": [
    "## 2. Part I: Linear Regression with PyTorch\n",
    "### 2.1. Simulate Data\n",
    "We generate synthetic data from the true relationship:\n",
    "$$ \n",
    "y=0.5x−1+ϵ,ϵ∼N(0,1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed706de",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20  # Number of data points\n",
    "\n",
    "# Input: uniform samples in [-5, +5]\n",
    "X = np.random.random(N) * 10 - 5\n",
    "\n",
    "# Target: linear rule + Gaussian noise\n",
    "Y = 0.5 * X - 1 + np.random.randn(N)\n",
    "\n",
    "# Visualize raw data\n",
    "plt.scatter(X, Y, label='Data')\n",
    "plt.title('Synthetic Linear Data')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfac846",
   "metadata": {},
   "source": [
    "### 2.2. Reshape for PyTorch\n",
    "PyTorch expects inputs as 2D tensors: (`batch_size`, `num_features`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8767f167",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(N, 1)  # Shape: (20, 1)\n",
    "Y = Y.reshape(N, 1)  # Shape: (20, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea922d9f",
   "metadata": {},
   "source": [
    "### 2.3. Convert to PyTorch Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848dfabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.from_numpy(X.astype(np.float32))\n",
    "targets = torch.from_numpy(Y.astype(np.float32))\n",
    "\n",
    "print(\"Input shape:\", inputs.shape)\n",
    "print(\"Target shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e9a6e6",
   "metadata": {},
   "source": [
    "### 2.4. Define the Model\n",
    "Use `nn.Linear(in_features=1`, `out_features=1` to create a model with:\n",
    "\n",
    "- Weight w (shape: [1, 1])\n",
    "- Bias b (shape: [1])\n",
    "$$\n",
    "\\hat{y} = \\mathbf{x} \\cdot \\mathbf{w} + b\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c69f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(1, 1)\n",
    "print(\"Initial parameters:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903ffb6f",
   "metadata": {},
   "source": [
    "### 2.5. Define Loss & Optimizer\n",
    "- Loss: Mean Squared Error (MSE)\n",
    "- Optimizer: Stochastic Gradient Descent (SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec10b72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eec0a9",
   "metadata": {},
   "source": [
    "### 2.6. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e09436",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 30\n",
    "losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # 1. Zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 2. Forward pass\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # 3. Compute loss\n",
    "    loss = criterion(outputs, targets)\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    # 4. Backward pass (compute gradients)\n",
    "    loss.backward()\n",
    "    \n",
    "    # 5. Update parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f'Epoch {epoch+1}/{n_epochs}, Loss: {loss.item():.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645e42f3",
   "metadata": {},
   "source": [
    "### 2.7. Visualize Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93769914",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be2726d",
   "metadata": {},
   "source": [
    "### 2.8. Plot Fitted Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c47b92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    predicted = model(inputs).numpy()\n",
    "\n",
    "plt.scatter(X, Y, label='Original data')\n",
    "plt.plot(X, predicted, color='red', label='Fitted line')\n",
    "plt.legend()\n",
    "plt.title('Linear Regression Fit')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67bfca3",
   "metadata": {},
   "source": [
    "### 2.9. Inspect Learned Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71f4b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = model.weight.data.item()\n",
    "b = model.bias.data.item()\n",
    "print(f\"Learned: y = {w:.3f} * x + {b:.3f}\")\n",
    "print(\"True:    y = 0.5 * x - 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12791c20",
   "metadata": {},
   "source": [
    "## 3. Saving & Loading Models\n",
    "### 3.1. Save Only Parameters (Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ffc5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"linear_model_weights.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2bb977",
   "metadata": {},
   "source": [
    "### 3.2. Load Parameters into a New Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d894a48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded = nn.Linear(1, 1)\n",
    "model_loaded.load_state_dict(torch.load(\"linear_model_weights.pth\"))\n",
    "model_loaded.eval()  # Set to evaluation mode\n",
    "\n",
    "# Verify prediction\n",
    "with torch.no_grad():\n",
    "    pred_loaded = model_loaded(inputs).numpy()\n",
    "\n",
    "plt.scatter(X, Y, label='Data')\n",
    "plt.plot(X, pred_loaded, '--', label='Loaded Model')\n",
    "plt.legend()\n",
    "plt.title('Model Loaded from state_dict()')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4b6b42",
   "metadata": {},
   "source": [
    "### 3.3. Save Entire Model (Less Flexible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f8e217",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"full_linear_model.pth\")\n",
    "model_v2 = torch.load(\"full_linear_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7650e5",
   "metadata": {},
   "source": [
    "### 3.4. TorchScript (For Deployment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4248ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_input = torch.randn(1, 1)\n",
    "scripted_model = torch.jit.trace(model, example_input)\n",
    "scripted_model.save(\"linear_model_traced.pt\")\n",
    "\n",
    "# Load in C++ or mobile without Python!\n",
    "loaded_ts = torch.jit.load(\"linear_model_traced.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54c543c",
   "metadata": {},
   "source": [
    "## 4. Part II: Nonlinear Neural Network — 3D Velocity Field\n",
    "### 4.1. Problem Statement\n",
    "We want to learn a mapping:\n",
    "$$ \n",
    "f_{\\theta} : (x, y, z, t) \\to (u, v, w)\n",
    "$$\n",
    "- Input: 4D spatiotemporal coordinates\n",
    "- Output: 3D velocity vector\n",
    "This is common in fluid dynamics, cosmology, or climate modeling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dee3af3",
   "metadata": {},
   "source": [
    "### 4.2. Model Architecture (MLP)\n",
    "| Layer | Input → Output | Activation |\n",
    "|-------|----------------|------------|\n",
    "| 1     | 4 → 10         | ReLU       |\n",
    "| 2     | 10 → 10        | ReLU       |\n",
    "| 3     | 10 → 3         | —          |\n",
    "\n",
    "### Option A: Using nn.Sequential (Quick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eea0479",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vel = nn.Sequential(\n",
    "    nn.Linear(4, 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e36ce6",
   "metadata": {},
   "source": [
    "### Option B: Custom Class (Flexible, Recommended for Science)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451a11ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VelocityFieldModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(4, 10)\n",
    "        self.layer2 = nn.Linear(10, 10)\n",
    "        self.layer3 = nn.Linear(10, 3)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate\n",
    "model_vel = VelocityFieldModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08276352",
   "metadata": {},
   "source": [
    "### 4.3. Simulate Training Data (Placeholder)\n",
    "In real applications, this would come from simulations or observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a5d158",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_vel = torch.randn(1000, 4)   # (x, y, z, t)\n",
    "targets_vel = torch.randn(1000, 3)  # (u, v, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc293eb1",
   "metadata": {},
   "source": [
    "### 4.4. Train the Velocity Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99dca83",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model_vel.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model_vel(inputs_vel)\n",
    "    loss = criterion(outputs, targets_vel)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoch {epoch}: Loss = {loss.item():.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
